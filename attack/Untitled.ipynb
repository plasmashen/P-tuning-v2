{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb07bce",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.1+cu110\n",
      "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1156.7 MB 12.1 MB/s eta 0:00:01    |███████▌                        | 271.1 MB 11.4 MB/s eta 0:01:19     |████████████▉                   | 464.3 MB 3.0 MB/s eta 0:03:50         | 488.3 MB 3.3 MB/s eta 0:03:22��███████████▋                | 565.3 MB 307 kB/s eta 0:32:06/s eta 0:00:54███████▋              | 635.0 MB 11.8 MB/s eta 0:00:45��█████████████▋              | 635.5 MB 11.8 MB/s eta 0:00:45████████              | 647.8 MB 11.2 MB/s eta 0:00:460:360 MB 9.9 MB/s eta 0:00:41        | 822.1 MB 10.4 MB/s eta 0:00:33        | 824.7 MB 10.4 MB/s eta 0:00:32█████████████         | 828.5 MB 10.4 MB/s eta 0:00:32█████▊        | 856.7 MB 1.3 MB/s eta 0:03:44     |████████████████████████        | 866.8 MB 1.4 MB/s eta 0:03:34██████▏       | 872.6 MB 1.4 MB/s eta 0:03:30    |████████████████████████▋       | 889.6 MB 1.4 MB/s eta 0:03:16�████▊       | 893.7 MB 1.4 MB/s eta 0:03:13     |████████████████████████▊       | 895.4 MB 1.4 MB/s eta 0:03:11███████       | 901.1 MB 11.3 MB/s eta 0:00:23��█████████████████       | 902.1 MB 11.3 MB/s eta 0:00:23     |█████████████████████████▉      | 931.9 MB 11.4 MB/s eta 0:00:20| 948.9 MB 11.2 MB/s eta 0:00:19████████████████████     | 975.9 MB 1.3 MB/s eta 0:02:20|███████████████████████████▊    | 1001.1 MB 12.5 MB/s eta 0:00:13��█████████████▉    | 1004.6 MB 303 kB/s eta 0:08:22████████████████████████████▏   | 1018.7 MB 13.0 MB/s eta 0:00:11    |████████████████████████████▎   | 1023.5 MB 13.0 MB/s eta 0:00:11    |████████████████████████████▍   | 1025.8 MB 13.0 MB/s eta 0:00:11██████████████████▋   | 1032.3 MB 13.0 MB/s eta 0:00:10��████████████████████████▊   | 1037.3 MB 15.3 MB/s eta 0:00:08    |████████████████████████████▉   | 1042.8 MB 15.3 MB/s eta 0:00:08    |█████████████████████████████   | 1046.8 MB 15.3 MB/s eta 0:00:08 MB 14.0 MB/s eta 0:00:08�████████████▏  | 1053.8 MB 14.0 MB/s eta 0:00:08█████████████████████████████▌  | 1066.1 MB 12.7 MB/s eta 0:00:08████▋  | 1069.2 MB 26.2 MB/s eta 0:00:04B/s eta 0:00:04 MB 13.9 MB/s eta 0:00:06█████  | 1088.3 MB 13.9 MB/s eta 0:00:05██████▋ | 1106.8 MB 13.5 MB/s eta 0:00:04████▉ | 1115.4 MB 607 kB/s eta 0:01:09█████ | 1118.1 MB 607 kB/s eta 0:01:04 MB 607 kB/s eta 0:01:02��███████████████ | 1123.0 MB 607 kB/s eta 0:00:561133.2 MB 13.8 MB/s eta 0:00:02��██████████████████████████▍| 1134.2 MB 13.8 MB/s eta 0:00:02 0:00:011151.0 MB 15.7 MB/s eta 0:00:01"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52231d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, tqdm, math, re, string,random\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, CosineSimilarity\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6085a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "\n",
    "def sent_pred(sent):\n",
    "    encoded_dict = tokenizer(sent,add_special_tokens = True,max_length = 256,\n",
    "                                         return_attention_mask = True,return_tensors = 'pt', truncation=True)   \n",
    "    iids = encoded_dict['input_ids'].to(device)\n",
    "    amasks = encoded_dict['attention_mask'].to(device)\n",
    "    p = bert(iids, token_type_ids=None, attention_mask=amasks)[0]\n",
    "    return torch.argmax(p).item()\n",
    "\n",
    "def sentences_pred(sents, batch_size=32):\n",
    "    encoded_dict = tokenizer(sents,add_special_tokens = True, max_length = 256, padding='max_length', \n",
    "                             return_attention_mask = True, return_tensors = 'pt',truncation=True)   \n",
    "    bert.to(device)\n",
    "    bert.eval()\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    input_mask = encoded_dict['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = bert(input_ids, token_type_ids=None, attention_mask=input_mask)[0]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "    return probs\n",
    "    return torch.cat(probs_all, dim=0)\n",
    "\n",
    "\n",
    "def importscore(text, sample=0):\n",
    "    random.seed(2020)\n",
    "    text_ls = text.split()\n",
    "    text_ls = text_ls[:200]\n",
    "#     no_text_ls = [(i,j) for i,j in enumerate(text_ls)]\n",
    "    len_text = len(text_ls)\n",
    "    if 0<sample<len_text:\n",
    "        leave_1_texts = [' '.join(text_ls[:ii] + text_ls[min(ii + 1, len_text):]) \n",
    "                         for ii in random.sample(list(range(len_text)),sample)]\n",
    "    else:\n",
    "        leave_1_texts = [' '.join(text_ls[:ii] + text_ls[min(ii + 1, len_text):]) for ii in range(len_text)]\n",
    "    leave_1_probs = sentences_pred([text]+leave_1_texts)\n",
    "    orig_probs = leave_1_probs[:1].squeeze()\n",
    "    orig_label = torch.argmax(orig_probs)\n",
    "    orig_prob = orig_probs.max()\n",
    "    leave_1_probs_argmax = torch.argmax(leave_1_probs[1:], dim=-1)\n",
    "    import_scores = (orig_prob - leave_1_probs[1:, orig_label]).data.cpu().numpy()\n",
    "    return import_scores\n",
    "\n",
    "def cal_AUC(orig_sent, adv_sent, k=0):\n",
    "    nms, nms1 = [], []\n",
    "    for i in tqdm.tqdm(range(int(len(orig_sent)))):\n",
    "        isa = importscore(adv_sent[i],k)\n",
    "        iso = importscore(orig_sent[i],k)\n",
    "        nms.append({'idx': i, 'isa': isa, 'iso': iso})\n",
    "    for i in nms:\n",
    "        isa_ = sorted(i['isa'],reverse=True)\n",
    "        iso_ = sorted(i['iso'],reverse=True)\n",
    "        entropyo = -np.mean([abs(i)*np.log(abs(i)) for i in iso_[:] if i!=0])\n",
    "        entropya = -np.mean([abs(i)*np.log(abs(i)) for i in isa_[:] if i!=0])\n",
    "    #     stdo, stda = np.std(iso_[:128]), np.std(isa_[:128])\n",
    "        nms1.append({'idx': i['idx'], 'entropyo': entropyo, 'entropya':entropya})\n",
    "    preds = [i['entropyo']for i in nms1]+[i['entropya']for i in nms1]\n",
    "    y_test = [0]*len(nms1)+[1]*len(nms1)\n",
    "    y_test = label_binarize(y_test, classes=[0, 1])\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test,preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc\n",
    "    \n",
    "def clean_str(string, TREC=False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip() if TREC else string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81eefefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from model.sequence_classification import (\n",
    "    BertPrefixForSequenceClassification,\n",
    "    BertPromptForSequenceClassification,\n",
    "    RobertaPrefixForSequenceClassification,\n",
    "    RobertaPromptForSequenceClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12454a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8f7bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert = AutoModelForSequenceClassification.from_pretrained('../checkpoints/amazon-bert-normal')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('../checkpoints/amazon-bert-normal', do_lower_case=True);\n",
    "# bert = BertPrefixForSequenceClassification.from_pretrained('../checkpoints/amazon-bert-prefix')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('../checkpoints/amazon-bert-prefix', do_lower_case=True);\n",
    "bert = BertPromptForSequenceClassification.from_pretrained('../checkpoints/amazon-bert-prompt')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../checkpoints/amazon-bert-prompt', do_lower_case=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8eb11e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful attacks: 313\n",
      "Number of failed attacks: 140\n",
      "Number of skipped attacks: 47\n",
      "Original accuracy: 90.6%\n",
      "Accuracy under attack: 28.0%\n",
      "Attack success rate: 69.09%\n",
      "Average perturbed word %: 24.91%\n",
      "Average num. words per input: 82.49\n",
      "Avg num queries: 206.54\n"
     ]
    }
   ],
   "source": [
    "f = open('adv_output/amazon-bert-prompt/textbugger/2022-07-02-21-53-log.txt')\n",
    "txt = f.read()\n",
    "text = txt.split('--------------------------------------------- Result ')\n",
    "for i in text[-1].split('\\n')[-10:-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34babcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sent_, adv_sent_, nms, nms2 = [], [], [], []\n",
    "count = 0\n",
    "for i in range(1,501):\n",
    "    tmp0 = text[i].split('\\n')\n",
    "    if 'FAILED' in tmp0[1] or 'SKIPPED' in tmp0[1]:\n",
    "        pass\n",
    "    else:\n",
    "        orig_sent_.append(tmp0[3])\n",
    "        adv_sent_.append(tmp0[5])\n",
    "orig_sent = [i.replace('[','').replace(']','') for i in orig_sent_]\n",
    "adv_sent = [i.replace('[','').replace(']','') for i in adv_sent_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f7ae070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:58<00:00,  2.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:00<00:00, 5251.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(int(len(orig_sent)))):\n",
    "    isa = importscore(adv_sent[i],20)\n",
    "    iso = importscore(orig_sent[i],20)\n",
    "    nms.append({'idx': i, 'isa': isa, 'iso': iso})\n",
    "for i in tqdm.tqdm(nms):\n",
    "    isa_ = sorted(i['isa'],reverse=True)\n",
    "    iso_ = sorted(i['iso'],reverse=True)\n",
    "    entropyo = -np.mean([abs(i)*np.log(abs(i)) for i in iso_[:] if i!=0])\n",
    "    entropya = -np.mean([abs(i)*np.log(abs(i)) for i in isa_[:] if i!=0])\n",
    "#     stdo, stda = np.std(iso_[:128]), np.std(isa_[:128])\n",
    "    nms2.append({'idx': i['idx'], 'entropyo': entropyo, 'entropya':entropya})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ced73b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844124161724627"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [i['entropyo']for i in nms2]+[i['entropya']for i in nms2]\n",
    "y_test = [0]*len(nms2)+[1]*len(nms2)\n",
    "y_test = label_binarize(y_test, classes=[0, 1])\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c8d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9f5b3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful attacks: 352\n",
      "Number of failed attacks: 101\n",
      "Number of skipped attacks: 47\n",
      "Original accuracy: 90.6%\n",
      "Accuracy under attack: 20.2%\n",
      "Attack success rate: 77.7%\n",
      "Average perturbed word %: 8.89%\n",
      "Average num. words per input: 82.49\n",
      "Avg num queries: 295.5\n"
     ]
    }
   ],
   "source": [
    "f = open('adv_output/amazon-bert-prompt/textfooler/2022-07-02-22-26-log.txt')\n",
    "txt = f.read()\n",
    "text = txt.split('--------------------------------------------- Result ')\n",
    "for i in text[-1].split('\\n')[-10:-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88ecbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sent_, adv_sent_, nms, nms2 = [], [], [], []\n",
    "count = 0\n",
    "for i in range(1,501):\n",
    "    tmp0 = text[i].split('\\n')\n",
    "    if 'FAILED' in tmp0[1] or 'SKIPPED' in tmp0[1]:\n",
    "        pass\n",
    "    else:\n",
    "        orig_sent_.append(tmp0[3])\n",
    "        adv_sent_.append(tmp0[5])\n",
    "orig_sent = [i.replace('[','').replace(']','') for i in orig_sent_]\n",
    "adv_sent = [i.replace('[','').replace(']','') for i in adv_sent_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e187237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 352/352 [02:13<00:00,  2.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 352/352 [00:00<00:00, 5614.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(int(len(orig_sent)))):\n",
    "    isa = importscore(adv_sent[i],20)\n",
    "    iso = importscore(orig_sent[i],20)\n",
    "    nms.append({'idx': i, 'isa': isa, 'iso': iso})\n",
    "for i in tqdm.tqdm(nms):\n",
    "    isa_ = sorted(i['isa'],reverse=True)\n",
    "    iso_ = sorted(i['iso'],reverse=True)\n",
    "    entropyo = -np.mean([abs(i)*np.log(abs(i)) for i in iso_[:] if i!=0])\n",
    "    entropya = -np.mean([abs(i)*np.log(abs(i)) for i in isa_[:] if i!=0])\n",
    "#     stdo, stda = np.std(iso_[:128]), np.std(isa_[:128])\n",
    "    nms2.append({'idx': i['idx'], 'entropyo': entropyo, 'entropya':entropya})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fbe5ad23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870092975206612"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [i['entropyo']for i in nms2]+[i['entropya']for i in nms2]\n",
    "y_test = [0]*len(nms2)+[1]*len(nms2)\n",
    "y_test = label_binarize(y_test, classes=[0, 1])\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134c62d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slj",
   "language": "python",
   "name": "slj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
